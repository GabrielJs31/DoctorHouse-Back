from faster_whisper import WhisperModel
from tqdm import tqdm
import os, time

# â–ŒCarpeta de audio relativa
BASE_DIR = os.path.dirname(__file__)
AUDIO_DIR = os.path.join(BASE_DIR, "audio")
os.makedirs(AUDIO_DIR, exist_ok=True)

# â–ŒRuta del archivo de entrada y salida
audio_path = os.path.join(AUDIO_DIR, "audio.wav")
output_path = os.path.splitext(audio_path)[0] + ".txt"  # audio/audio.txt

# â–ŒCONFIGURACIÃ“N DEL MODELO SOLO CPU
model = WhisperModel("small", device="cpu", compute_type="int8")

# â–ŒTIEMPO DE EJECUCIÃ“N
start_time = time.time()

# â–ŒTRANSCRIPCIÃ“N
segments, info = model.transcribe(audio_path, beam_size=1, vad_filter=True)
print("ğŸŒ Idioma detectado: '%s' (probabilidad %.2f)" % (info.language, info.language_probability))

transcription = []
print("ğŸ“ Iniciando transcripciÃ³n...")
for segment in tqdm(segments, desc="â³ Transcribiendo", unit="segmento"):
    transcription.append("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))

# â–ŒGUARDAR TRANSCRIPCIÃ“N
with open(output_path, "w", encoding="utf-8") as f:
    f.write("\n".join(transcription))

# â–ŒTIEMPO FINAL
elapsed = time.time() - start_time
minutes = int(elapsed // 60)
seconds = int(elapsed % 60)

print(f"\nâœ… TranscripciÃ³n guardada en:\n{output_path}")
print(f"â±ï¸ Tiempo total de transcripciÃ³n: {minutes} minutos y {seconds} segundos")
